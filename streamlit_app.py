# -*- coding: utf-8 -*-
import os
import json
import streamlit as st
import pandas as pd
import numpy as np

# ì§€ë„
import folium
from folium.features import GeoJson, GeoJsonTooltip, GeoJsonPopup
from streamlit_folium import st_folium

st.set_page_config(page_title="Nomad ì¶”ì²œ ëŒ€ì‹œë³´ë“œ", layout="wide")

# =========================================================
# ê²½ë¡œ í›„ë³´
# =========================================================
CANDIDATE_BASES = [
    r"C:\Users\123cl\OneDrive\ë°”íƒ• í™”ë©´\test",  # Windows OneDrive
    "/mnt/data",                                # ë¦¬ëˆ…ìŠ¤/ë…¸íŠ¸ë¶
    ".",                                        # í˜„ì¬ í´ë”
]

def build_paths():
    for base in CANDIDATE_BASES:
        fv = os.path.join(base, "20250809144224_ê´‘ì—­ë³„ ë°©ë¬¸ì ìˆ˜.csv")
        fc = os.path.join(base, "PLP_ì—…ì¢…ë³„_ê²€ìƒ‰ê±´ìˆ˜_í†µí•©.csv")
        ft = os.path.join(base, "PLP_ìœ í˜•ë³„_ê²€ìƒ‰ê±´ìˆ˜_í†µí•©.csv")
        if all(os.path.exists(p) for p in [fv, fc, ft]):
            return fv, fc, ft
    return fv, fc, ft

file_visitors, file_spend_cat, file_spend_type = build_paths()

def resolve_geojson_path():
    candidates = [
        os.path.join(CANDIDATE_BASES[0], "korea_provinces.geojson"),
        os.path.join(CANDIDATE_BASES[0], "KOREA_GEOJSON.geojson"),
        "/mnt/data/korea_provinces.geojson",
        "/mnt/data/KOREA_GEOJSON.geojson",
    ]
    for p in candidates:
        if os.path.exists(p):
            return p
    return ""

KOREA_GEOJSON = resolve_geojson_path()

# êµ­ë‚´ GeoJSONì˜ ì§€ì—­ëª… í‚¤ í›„ë³´ (KOSTAT 2018 í˜¸í™˜: name ìš°ì„ )
GEO_PROP_KEYS = ["name", "CTPRVN_NM", "ADM1_KOR_NM", "sido_nm", "SIG_KOR_NM", "NAME_1"]

# =========================================================
# ì•ˆì „ GeoJSON ë¡œë” + ìºì‹œ
# =========================================================
@st.cache_data(show_spinner=False)
def load_geojson_safe(path: str):
    import re
    if not path or not os.path.exists(path):
        return None, "missing_path"
    try:
        if os.path.getsize(path) == 0:
            return None, "empty_file"
    except Exception:
        pass

    encodings = (
        "utf-8", "utf-8-sig", "utf-16", "utf-16-le", "utf-16-be",
        "cp949", "euc-kr", "latin-1"
    )
    last_err = None
    for enc in encodings:
        try:
            with open(path, "r", encoding=enc, errors="strict") as f:
                txt = f.read().strip()
            if not txt:
                return None, f"empty_text({enc})"
            if txt.lstrip().startswith(("var ", "const ", "let ")):  # JS ë³€ìˆ˜ ë˜í•‘
                m = re.search(r"\{.*\}\s*;?\s*$", txt, flags=re.S)
                if m:
                    txt = m.group(0)
            gj = json.loads(txt)
            if not isinstance(gj, dict):
                return None, f"not_dict({enc})"
            if gj.get("type") == "Topology":
                return None, "topojson_not_supported"
            if gj.get("type") != "FeatureCollection" or not isinstance(gj.get("features"), list):
                return None, f"not_featurecollection({enc})"
            return gj, None
        except Exception as e:
            last_err = f"{enc}: {e}"
            continue
    return None, last_err or "unknown_error"

# === ì§€ì—­(ê´‘ì—­) ì¤‘ì‹¬ì  ì¢Œí‘œ (ëŒ€ëµê°’) ===
REGION_COORDS = {
    "ì„œìš¸": (37.5665, 126.9780), "ë¶€ì‚°": (35.1796, 129.0756), "ëŒ€êµ¬": (35.8714, 128.6014),
    "ì¸ì²œ": (37.4563, 126.7052), "ê´‘ì£¼": (35.1595, 126.8526), "ëŒ€ì „": (36.3504, 127.3845),
    "ìš¸ì‚°": (35.5384, 129.3114), "ì„¸ì¢…": (36.4800, 127.2890), "ê²½ê¸°": (37.4138, 127.5183),
    "ê°•ì›": (37.8228, 128.1555), "ì¶©ë¶": (36.6357, 127.4913), "ì¶©ë‚¨": (36.5184, 126.8000),
    "ì „ë¶": (35.7175, 127.1530), "ì „ë‚¨": (34.8679, 126.9910), "ê²½ë¶": (36.4919, 128.8889),
    "ê²½ë‚¨": (35.4606, 128.2132), "ì œì£¼": (33.4996, 126.5312),
}

# ---------- CSV ë¡œë”(ìµœì í™”: í•„ìš”í•œ ì»¬ëŸ¼ë§Œ, ìºì‹œ) ----------
NEEDED_VIS_COLS = ["ê´‘ì—­ì§€ìì²´ëª…", "ê¸°ì´ˆì§€ìì²´ ë°©ë¬¸ì ìˆ˜"]
NEEDED_PLP_COLS = ["ì§€ì—­", "ëŒ€ë¶„ë¥˜", "ì¤‘ë¶„ë¥˜", "ëŒ€ë¶„ë¥˜ ì§€ì¶œì•¡ ë¹„ìœ¨", "ì¤‘ë¶„ë¥˜ ì§€ì¶œì•¡ ë¹„ìœ¨"]

@st.cache_data(show_spinner=False)
def read_csv_forgiving(path, usecols=None, dtype=None):
    for enc in ["utf-8", "cp949", "euc-kr"]:
        try:
            return pd.read_csv(path, encoding=enc, usecols=usecols, dtype=dtype)
        except Exception:
            continue
    return pd.read_csv(path, usecols=usecols, dtype=dtype)

@st.cache_data(show_spinner=False)
def read_data():
    vis = read_csv_forgiving(file_visitors, usecols=NEEDED_VIS_COLS, dtype={"ê´‘ì—­ì§€ìì²´ëª…": "string"})
    cat = read_csv_forgiving(file_spend_cat, usecols=NEEDED_PLP_COLS,
                             dtype={"ì§€ì—­": "string", "ëŒ€ë¶„ë¥˜": "string", "ì¤‘ë¶„ë¥˜": "string"})
    typ = read_csv_forgiving(file_spend_type, usecols=NEEDED_PLP_COLS,
                             dtype={"ì§€ì—­": "string", "ëŒ€ë¶„ë¥˜": "string", "ì¤‘ë¶„ë¥˜": "string"})
    # ë¬¸ìì—´ ì••ì¶•
    for df in (cat, typ):
        for c in ["ì§€ì—­", "ëŒ€ë¶„ë¥˜", "ì¤‘ë¶„ë¥˜"]:
            if c in df.columns:
                df[c] = df[c].astype("category")
    return vis, cat, typ

# =============== ë°ì´í„° ë¡œë“œ ===============
try:
    vis, cat, typ = read_data()
except Exception as e:
    st.error(
        f"ë°ì´í„° íŒŒì¼ì„ ì°¾ê±°ë‚˜ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"
        f"- ë°©ë¬¸ì ìˆ˜: {file_visitors}\n- ì—…ì¢…ë³„: {file_spend_cat}\n- ìœ í˜•ë³„: {file_spend_type}\n\n{e}"
    )
    st.stop()

# =============== ì „ì²˜ë¦¬/ì§€í‘œ ê³„ì‚° ===============
def normalize_region_name(s: str) -> str:
    if s is None:
        return ""
    s = str(s).strip()
    for a in ["íŠ¹ë³„ìì¹˜ë„","íŠ¹ë³„ìì¹˜ì‹œ","íŠ¹ë³„ì‹œ","ê´‘ì—­ì‹œ","ìì¹˜ë„","ìì¹˜ì‹œ","ë„","ì‹œ"]:
        s = s.replace(a, "")
    return " ".join(s.split())

def compute_overall_share(df):
    df = df.copy()
    for c in ["ëŒ€ë¶„ë¥˜ ì§€ì¶œì•¡ ë¹„ìœ¨", "ì¤‘ë¶„ë¥˜ ì§€ì¶œì•¡ ë¹„ìœ¨"]:
        df[c] = pd.to_numeric(df[c], errors="coerce")
    df["ëŒ€ë¶„ë¥˜_f"] = df["ëŒ€ë¶„ë¥˜ ì§€ì¶œì•¡ ë¹„ìœ¨"] / 100.0
    df["ì¤‘ë¶„ë¥˜_f"] = df["ì¤‘ë¶„ë¥˜ ì§€ì¶œì•¡ ë¹„ìœ¨"] / 100.0
    df["ì¤‘ë¶„ë¥˜_ì „ì²´ë¹„ì¤‘"] = df["ëŒ€ë¶„ë¥˜_f"] * df["ì¤‘ë¶„ë¥˜_f"]
    return df

# ë°©ë¬¸ì ì ìœ ìœ¨
vis_region = (
    vis.groupby("ê´‘ì—­ì§€ìì²´ëª…", as_index=False)["ê¸°ì´ˆì§€ìì²´ ë°©ë¬¸ì ìˆ˜"]
      .sum()
      .rename(columns={"ê¸°ì´ˆì§€ìì²´ ë°©ë¬¸ì ìˆ˜": "ë°©ë¬¸ììˆ˜_í•©ê³„"})
)
total_visitors = max(vis_region["ë°©ë¬¸ììˆ˜_í•©ê³„"].sum(), 1)
vis_region["ë°©ë¬¸ì_ì ìœ ìœ¨"] = vis_region["ë°©ë¬¸ììˆ˜_í•©ê³„"] / total_visitors
vis_region["ì§€ì—­_norm"] = vis_region["ê´‘ì—­ì§€ìì²´ëª…"].map(normalize_region_name)

# ì†Œë¹„/ìœ í˜• ë‹¤ì–‘ì„± & ìˆ™ë°• ë¹„ì¤‘
cat2 = compute_overall_share(cat)
typ2 = compute_overall_share(typ)

# region-level metrics (cat2)
region_cat = []
for region, g in cat2.groupby("ì§€ì—­"):
    s = g["ì¤‘ë¶„ë¥˜_ì „ì²´ë¹„ì¤‘"].dropna().values
    if len(s) > 0 and s.sum() > 0:
        p = s / s.sum()
        H = -(p * np.log(p)).sum()
        Hmax = np.log(len(p))
        div = H / Hmax if Hmax > 0 else 0.0
    else:
        div = np.nan
    lodg = pd.to_numeric(g.loc[g["ëŒ€ë¶„ë¥˜"] == "ìˆ™ë°•ì—…", "ëŒ€ë¶„ë¥˜ ì§€ì¶œì•¡ ë¹„ìœ¨"], errors="coerce")
    lodg_share = float(lodg.mean()) if len(lodg) else np.nan
    region_cat.append({"ì§€ì—­": region, "ì†Œë¹„_ë‹¤ì–‘ì„±ì§€ìˆ˜": div, "ìˆ™ë°•_ì§€ì¶œë¹„ì¤‘(%)": lodg_share})
region_cat = pd.DataFrame(region_cat)
region_cat["ì§€ì—­_norm"] = region_cat["ì§€ì—­"].map(normalize_region_name)

# region-level metrics (typ2)
region_typ = []
for region, g in typ2.groupby("ì§€ì—­"):
    s = g["ì¤‘ë¶„ë¥˜_ì „ì²´ë¹„ì¤‘"].dropna().values
    if len(s) > 0 and s.sum() > 0:
        p = s / s.sum()
        H = -(p * np.log(p)).sum()
        Hmax = np.log(len(p))
        div_t = H / Hmax if Hmax > 0 else 0.0
    else:
        div_t = np.nan
    region_typ.append({"ì§€ì—­": region, "í™œë™_ë‹¤ì–‘ì„±ì§€ìˆ˜": div_t})
region_typ = pd.DataFrame(region_typ)
region_typ["ì§€ì—­_norm"] = region_typ["ì§€ì—­"].map(normalize_region_name)

# í†µí•© ë©”íŠ¸ë¦­
metrics = (
    vis_region.merge(region_cat.drop(columns=["ì§€ì—­"]), on="ì§€ì—­_norm", how="left")
              .merge(region_typ.drop(columns=["ì§€ì—­"]), on="ì§€ì—­_norm", how="left")
)

def minmax(s):
    s = s.astype(float)
    return (s - s.min()) / (s.max() - s.min()) if s.max() > s.min() else s * 0

metrics["ë°©ë¬¸ì_ì ìœ ìœ¨_norm"] = minmax(metrics["ë°©ë¬¸ì_ì ìœ ìœ¨"].fillna(0))
metrics["ì†Œë¹„_ë‹¤ì–‘ì„±_norm"]   = minmax(metrics["ì†Œë¹„_ë‹¤ì–‘ì„±ì§€ìˆ˜"].fillna(0))
metrics["ìˆ™ë°•_ë¹„ì¤‘_norm"]     = minmax(metrics["ìˆ™ë°•_ì§€ì¶œë¹„ì¤‘(%)"].fillna(0))
metrics["í™œë™_ë‹¤ì–‘ì„±_norm"]   = minmax(metrics["í™œë™_ë‹¤ì–‘ì„±ì§€ìˆ˜"].fillna(0))

# ê¸°ë³¸ NSI(ì²´í¬ë°•ìŠ¤ ì ìš© ì „ ê¸°ë³¸ ê°€ì¤‘ì¹˜)
BASE_WEIGHTS = dict(vis=0.30, div=0.30, lodg=0.20, act=0.20)
def base_nsi(df):
    return (
        BASE_WEIGHTS["vis"]  * df["ë°©ë¬¸ì_ì ìœ ìœ¨_norm"] +
        BASE_WEIGHTS["div"]  * df["ì†Œë¹„_ë‹¤ì–‘ì„±_norm"] +
        BASE_WEIGHTS["lodg"] * df["ìˆ™ë°•_ë¹„ì¤‘_norm"] +
        BASE_WEIGHTS["act"]  * df["í™œë™_ë‹¤ì–‘ì„±_norm"]
    )
metrics["NSI_base"] = base_nsi(metrics)

# ì¢Œí‘œ DF
coords_df = pd.DataFrame([{"ì§€ì—­_norm": k, "lat": v[0], "lon": v[1]} for k, v in REGION_COORDS.items()])
metrics_map = metrics.merge(coords_df, on="ì§€ì—­_norm", how="left")

# =====================================================
# UI (ì¢Œ: ì§€ë„ / ìš°: ì»¤ë®¤ë‹ˆí‹° íŒ¨ë„)
# =====================================================
st.title("ë””ì§€í„¸ ë…¸ë§ˆë“œ ì§€ì—­ ì¶”ì²œ ëŒ€ì‹œë³´ë“œ")

left, right = st.columns([2, 1])

with left:
    st.subheader("ì§€ë„ì—ì„œ ì§€ì—­ì„ ì„ íƒí•˜ì„¸ìš”")

# ì‚¬ì´ë“œë°” í•„í„°ë“¤ ------------------------------------------------
st.sidebar.header("ì¶”ì²œ ì¹´í…Œê³ ë¦¬ ì„ íƒ")
st.sidebar.caption("ì—¬ëŸ¬ ì¡°ê±´ì„ ì„ íƒí•˜ì„¸ìš”. (í•„í„° + ë³´ë„ˆìŠ¤ ê°€ì¤‘)")
colA1, colA2 = st.sidebar.columns(2)
with colA1:
    cb_popular = st.checkbox("ğŸ”¥ Popular now", value=False)
    cb_toprank = st.checkbox("ğŸ… Top ranked", value=True)
    cb_hidden  = st.checkbox("ğŸ’ Hidden gem", value=False)
with colA2:
    cb_act_rich = st.checkbox("ğŸ¯ Activity-rich", value=False)
    cb_lodging  = st.checkbox("ğŸ›ï¸ Lodging-ready", value=False)
    cb_diverse  = st.checkbox("ğŸ›ï¸ Diverse consumption", value=False)

st.sidebar.markdown("---")
st.sidebar.caption("ì¶”ê°€ ì§€í‘œ(í•´ë‹¹ ì»¬ëŸ¼ì´ ìˆì„ ë•Œ ìë™ ë°˜ì˜)")
colB1, colB2 = st.sidebar.columns(2)
with colB1:
    cb_budget  = st.checkbox("ğŸ’° Budget-friendly", value=False)
    cb_fastnet = st.checkbox("ğŸš€ Fast internet", value=False)
with colB2:
    cb_cleanair = st.checkbox("ğŸ’¨ Clean air now", value=False)
    cb_safe     = st.checkbox("ğŸ›¡ï¸ Safe", value=False)

st.sidebar.markdown("---")
match_mode = st.sidebar.radio("í•„í„° ê²°í•© ë°©ì‹", ["ANY(í•˜ë‚˜ ì´ìƒ ì¶©ì¡±)", "ALL(ëª¨ë‘ ì¶©ì¡±)"], index=0)
filter_strength = st.sidebar.slider("í•„í„° ê°•ë„", 0.0, 1.0, 0.5, 0.05)
bonus_strength  = st.sidebar.slider("ë³´ë„ˆìŠ¤ ê°€ì¤‘", 0.0, 0.5, 0.20, 0.01)

# --------------------------------------------------------------
def apply_category_rules(df):
    g0 = df.copy()
    notes = []

    q_vis_hi = g0["ë°©ë¬¸ì_ì ìœ ìœ¨_norm"].quantile(0.70)
    q_vis_lo = g0["ë°©ë¬¸ì_ì ìœ ìœ¨_norm"].quantile(0.40)
    q_nsi_hi = g0["NSI_base"].quantile(0.70)
    q_div_hi = g0["ì†Œë¹„_ë‹¤ì–‘ì„±_norm"].quantile(0.70)
    q_lod_hi = g0["ìˆ™ë°•_ë¹„ì¤‘_norm"].quantile(0.70)
    q_act_hi = g0["í™œë™_ë‹¤ì–‘ì„±_norm"].quantile(0.70)

    conds = []
    if cb_popular:
        conds.append(g0["ë°©ë¬¸ì_ì ìœ ìœ¨_norm"] >= (q_vis_hi * (1 - 0.3 * filter_strength)))
        notes.append("Popular now: ë°©ë¬¸ì ìƒìœ„")
    if cb_toprank:
        conds.append(g0["NSI_base"] >= (q_nsi_hi * (1 - 0.3 * filter_strength)))
        notes.append("Top ranked: NSI ìƒìœ„")
    if cb_hidden:
        conds.append((g0["ë°©ë¬¸ì_ì ìœ ìœ¨_norm"] <= (q_vis_lo * (1 + 0.3 * filter_strength))) & (g0["NSI_base"] >= q_nsi_hi))
        notes.append("Hidden gem: ë°©ë¬¸ì í•˜ìœ„ & NSI ìƒìœ„")
    if cb_act_rich:
        conds.append(g0["í™œë™_ë‹¤ì–‘ì„±_norm"] >= (q_act_hi * (1 - 0.3 * filter_strength)))
        notes.append("Activity-rich: í™œë™ ë‹¤ì–‘ì„± ìƒìœ„")
    if cb_lodging:
        conds.append(g0["ìˆ™ë°•_ë¹„ì¤‘_norm"] >= (q_lod_hi * (1 - 0.3 * filter_strength)))
        notes.append("Lodging-ready: ìˆ™ë°• ë¹„ì¤‘ ìƒìœ„")
    if cb_diverse:
        conds.append(g0["ì†Œë¹„_ë‹¤ì–‘ì„±_norm"] >= (q_div_hi * (1 - 0.3 * filter_strength)))
        notes.append("Diverse consumption: ì†Œë¹„ ë‹¤ì–‘ì„± ìƒìœ„")

    if len(conds) == 0:
        g = g0.copy()
    else:
        if "ALL" in match_mode:
            mask = np.logical_and.reduce(conds)
            g = g0.loc[mask].copy()
            if g.empty:
                mask = np.logical_or.reduce(conds)
                g = g0.loc[mask].copy()
                notes.append("âš ï¸ ALLâ†’ê²°ê³¼ ì—†ìŒ â†’ ANYë¡œ ì™„í™”")
        else:
            mask = np.logical_or.reduce(conds)
            g = g0.loc[mask].copy()
            if g.empty:
                g = g0.copy()
                notes.append("âš ï¸ ê²°ê³¼ ì—†ìŒ â†’ í•„í„° í•´ì œ")

    bonus = np.zeros(len(g))
    def add_bonus(series, strong_q): return bonus_strength * (series - strong_q).clip(lower=0)

    if cb_popular: bonus += add_bonus(g["ë°©ë¬¸ì_ì ìœ ìœ¨_norm"], q_vis_hi)
    if cb_toprank: bonus += add_bonus(g["NSI_base"], q_nsi_hi)
    if cb_act_rich: bonus += add_bonus(g["í™œë™_ë‹¤ì–‘ì„±_norm"], q_act_hi)
    if cb_lodging:  bonus += add_bonus(g["ìˆ™ë°•_ë¹„ì¤‘_norm"], q_lod_hi)
    if cb_diverse:  bonus += add_bonus(g["ì†Œë¹„_ë‹¤ì–‘ì„±_norm"], q_div_hi)

    def has_col(col): return col in g.columns and pd.api.types.is_numeric_dtype(g[col])
    if cb_budget and has_col("cost_index"):
        rng = (g["cost_index"].max() - g["cost_index"].min()) + 1e-9
        tmp = 1 - ((g["cost_index"] - g["cost_index"].min()) / rng)
        bonus += bonus_strength * tmp
        notes.append("Budget: cost_index ì ìš©")
    if cb_fastnet and has_col("internet_mbps"):
        rng = (g["internet_mbps"].max() - g["internet_mbps"].min()) + 1e-9
        tmp = (g["internet_mbps"] - g["internet_mbps"].min()) / rng
        bonus += bonus_strength * tmp
        notes.append("Fast net: internet_mbps ì ìš©")
    if cb_cleanair and has_col("air_quality_pm25"):
        rng = (g["air_quality_pm25"].max() - g["air_quality_pm25"].min()) + 1e-9
        tmp = 1 - ((g["air_quality_pm25"] - g["air_quality_pm25"].min()) / rng)
        bonus += bonus_strength * tmp
        notes.append("Clean air: pm2.5 ì ìš©")
    if cb_safe and has_col("safety_index"):
        rng = (g["safety_index"].max() - g["safety_index"].min()) + 1e-9
        tmp = (g["safety_index"] - g["safety_index"].min()) / rng
        bonus += bonus_strength * tmp
        notes.append("Safe: safety_index ì ìš©")

    g["NSI"] = g["NSI_base"] + bonus
    return g, notes

# ======== ë©”íŠ¸ë¦­/ë­í‚¹ ìƒì„± ========
metrics_after_rules, applied_notes = apply_category_rules(metrics_map)
if "selected_region" not in st.session_state:
    st.session_state.selected_region = None

sel_region = st.session_state.selected_region
selected_norm = normalize_region_name(sel_region) if sel_region else None

ranked = metrics_after_rules.copy()
ranked["rank"] = ranked["NSI"].rank(ascending=False, method="min").astype(int)

# ìƒ‰ìƒ
COLOR_TOP1, COLOR_TOP2, COLOR_TOP3 = "#ff6b6b", "#ffd43b", "#4dabf7"
COLOR_SEL, COLOR_BASE = "#94d82d", "#b8c0cc"

def pick_color(region_norm, selected_region_norm=None):
    if selected_region_norm and region_norm == selected_region_norm:
        return COLOR_SEL
    r = int(ranked.loc[ranked["ì§€ì—­_norm"] == region_norm, "rank"].min()) if region_norm in ranked["ì§€ì—­_norm"].values else 999
    return {1: COLOR_TOP1, 2: COLOR_TOP2, 3: COLOR_TOP3}.get(r, COLOR_BASE)

# =================== ì§€ë„(ì™¼ìª½) ===================
with left:
    m = folium.Map(
        location=[36.5, 127.8],
        zoom_start=7,
        tiles="cartodbpositron",
        prefer_canvas=True   # ë Œë” ìµœì í™”
    )

    gj, gj_err = (None, "no_path")
    if KOREA_GEOJSON and os.path.exists(KOREA_GEOJSON):
        gj, gj_err = load_geojson_safe(KOREA_GEOJSON)

    if gj is None:
        st.warning(f"GeoJSON ë¡œë“œ ì‹¤íŒ¨ â†’ ë§ˆì»¤ ëª¨ë“œ, ì›ì¸: {gj_err}")
        # í´ë¦¬ê³¤ ì‹¤íŒ¨ ì‹œ ë§ˆì»¤ ëª¨ë“œ
        for _, r in ranked.iterrows():
            if pd.isna(r.get("lat")) or pd.isna(r.get("lon")): continue
            color = pick_color(r["ì§€ì—­_norm"], selected_norm)
            nsi = float(r.get("NSI", r.get("NSI_base", 0.0)))
            size = 6 + 14 * nsi
            folium.CircleMarker(
                location=[r["lat"], r["lon"]],
                radius=size, color=color, fill=True, fill_color=color,
                fill_opacity=0.75, opacity=0.9 if color != COLOR_BASE else 0.6,
                weight=2 if color != COLOR_BASE else 1
            ).add_to(m)
    else:
        # REGION_NAME ì£¼ì…
        for ft in gj.get("features", []):
            props = ft.get("properties", {})
            region_raw = None
            for k in GEO_PROP_KEYS:
                if k in props and props[k]:
                    region_raw = props[k]; break
            if region_raw is None:
                textish = [str(v) for v in props.values() if isinstance(v, str)]
                region_raw = max(textish, key=len) if textish else ""
            props["REGION_NAME"] = normalize_region_name(region_raw)

        def style_function(feature):
            rname = feature["properties"].get("REGION_NAME", "")
            color = pick_color(rname, selected_norm)
            return {
                "fillColor": color, "color": color,
                "weight": 2 if color != COLOR_BASE else 1,
                "fillOpacity": 0.45 if color != COLOR_BASE else 0.25,
                "opacity": 0.9 if color != COLOR_BASE else 0.6,
            }

        def highlight_function(feature):
            return {"fillOpacity": 0.75, "weight": 3}

        GeoJson(
            gj,
            name="regions",
            style_function=style_function,
            highlight_function=highlight_function,
            smooth_factor=1.0,   # ê²½ê³„ ê°„ì†Œí™”(ë Œë” ê°€ë²¼ì›€)
            tooltip=GeoJsonTooltip(
                fields=["REGION_NAME"], labels=False, sticky=True,
                style=("background-color: rgba(32,32,32,0.85); color: white; "
                       "font-size: 12px; padding: 6px 8px; border-radius: 6px;"),
            ),
            popup=GeoJsonPopup(fields=["REGION_NAME"], labels=False),
        ).add_to(m)

        # ë²”ë¡€(1~3ìœ„)
        legend_html = f"""
        <div style="
          position: fixed; bottom: 20px; left: 20px; z-index: 9999;
          background: rgba(255,255,255,0.96); padding: 12px 14px; border-radius: 10px;
          box-shadow: 0 2px 10px rgba(0,0,0,0.15); font-size: 13px; color: #222;">
          <div style="font-weight:700; margin-bottom:8px;">ë­í‚¹</div>
          <div style="display:flex; align-items:center; gap:8px; margin:4px 0;">
            <span style="display:inline-block;width:14px;height:14px;background:{COLOR_TOP1};
                         border:1px solid rgba(0,0,0,.2);border-radius:3px;"></span>
            <span>1ìœ„ Â· ìµœìƒìœ„ ì§€ì—­</span>
          </div>
          <div style="display:flex; align-items:center; gap:8px; margin:4px 0;">
            <span style="display:inline-block;width:14px;height:14px;background:{COLOR_TOP2};
                         border:1px solid rgba(0,0,0,.2);border-radius:3px;"></span>
            <span>2ìœ„ Â· ìƒìœ„ê¶Œ ì§€ì—­</span>
          </div>
          <div style="display:flex; align-items:center; gap:8px; margin:4px 0;">
            <span style="display:inline-block;width:14px;height:14px;background:{COLOR_TOP3};
                         border:1px solid rgba(0,0,0,.2);border-radius:3px;"></span>
            <span>3ìœ„ Â· ìœ ë§ ì§€ì—­</span>
          </div>
        </div>"""
        m.get_root().html.add_child(folium.Element(legend_html))

    # ì§€ë„ë¥¼ ì¡°ê¸ˆ ë” ì‘ê²Œ(ë†’ì´ 420)
    MAP_KEY = "main_map"
    map_state = st_folium(m, width=None, height=420, key=MAP_KEY)

    # í´ë¦­ ë””ë°”ìš´ìŠ¤
    clicked = map_state.get("last_object_clicked_popup")
    prev_clicked = st.session_state.get("_last_clicked")
    if clicked and clicked != prev_clicked:
        st.session_state.selected_region = normalize_region_name(str(clicked))
        st.session_state._last_clicked = clicked

# =================== ì»¤ë®¤ë‹ˆí‹° íŒ¨ë„(ì˜¤ë¥¸ìª½) ===================
with right:
    st.subheader("ì»¤ë®¤ë‹ˆí‹°")
    # ì¹´ë“œ ìŠ¤íƒ€ì¼ ì»¨í…Œì´ë„ˆ
    st.markdown(
        """
        <div style="
            background: rgba(255,255,255,0.95);
            border: 1px solid rgba(0,0,0,0.06);
            border-radius: 12px;
            padding: 16px 16px 6px 16px;">
            <div style="font-weight:700; font-size:16px; margin-bottom:10px;">
                ì—­í•  ì„ íƒ
            </div>
        </div>
        """, unsafe_allow_html=True
    )
    # ì‹¤ì œ ì¸í„°ë™ì…˜ ìœ„ì ¯
    role_col1, role_col2 = st.columns(2)
    with role_col1:
        buddy_on = st.toggle("ğŸ§‘â€ğŸ¤â€ğŸ§‘ ë²„ë”” ì„ íƒ", value=False, help="ì§€ì—­ ì²­ë…„/í•™ìƒ ë²„ë””ë¡œ ì°¸ì—¬")
    with role_col2:
        tourist_on = st.toggle("ğŸ§³ ê´€ê´‘ê° ì„ íƒ", value=False, help="ì²´ë¥˜/ì—¬í–‰ìë¡œ ì°¸ì—¬")

    # ìƒíƒœ í‘œì‹œ
    st.caption("ì„ íƒ ìƒíƒœ")
    st.write(
        f"- ë²„ë””: **{'ì°¸ì—¬' if buddy_on else 'ë¯¸ì°¸ì—¬'}**  |  "
        f"ê´€ê´‘ê°: **{'ì°¸ì—¬' if tourist_on else 'ë¯¸ì°¸ì—¬'}**"
    )

# =================== ì´í•˜: ë­í‚¹/í‚¤ì›Œë“œ ì„¹ì…˜ ===================
st.subheader("ì¶”ì²œ ë­í‚¹")
rec = ranked.sort_values("NSI", ascending=False)[
    ["ê´‘ì—­ì§€ìì²´ëª…","NSI","NSI_base","ë°©ë¬¸ììˆ˜_í•©ê³„","ë°©ë¬¸ì_ì ìœ ìœ¨",
     "ìˆ™ë°•_ì§€ì¶œë¹„ì¤‘(%)","ì†Œë¹„_ë‹¤ì–‘ì„±ì§€ìˆ˜","í™œë™_ë‹¤ì–‘ì„±ì§€ìˆ˜"]
]
st.dataframe(rec.reset_index(drop=True), use_container_width=True)
st.download_button(
    "â¬‡ï¸ ë­í‚¹ CSV ì €ì¥",
    rec.to_csv(index=False).encode("utf-8-sig"),
    file_name="ranking_by_categories.csv",
    mime="text/csv"
)

st.subheader("í‚¤ì›Œë“œ Â· ì¹´í…Œê³ ë¦¬ íƒìƒ‰ (ì—…ì¢…/ìœ í˜• ê²€ìƒ‰ë¹„ì¤‘ ê¸°ë°˜)")
col1, col2, col3 = st.columns(3)
with col1:
    st.text_input("ì§€ì—­", st.session_state.selected_region or "", disabled=True)
with col2:
    sel_big = st.selectbox("ëŒ€ë¶„ë¥˜ ì„ íƒ(ì—…ì¢…)", ["--ì „ì²´--"] + sorted(cat["ëŒ€ë¶„ë¥˜"].cat.categories.tolist()))
with col3:
    kw = st.text_input("í‚¤ì›Œë“œ(ì¤‘ë¶„ë¥˜ëª… ë¶€ë¶„ ì¼ì¹˜)", "")

def top_keywords(df, region, big=None, keyword="", topn=10):
    region_normed = normalize_region_name(region or "")
    g = df[df["ì§€ì—­"].astype(str).map(normalize_region_name) == region_normed].copy()
    if big and big != "--ì „ì²´--":
        g = g[g["ëŒ€ë¶„ë¥˜"] == big]
    if keyword:
        g = g[g["ì¤‘ë¶„ë¥˜"].astype(str).str.contains(keyword, case=False, na=False)]
    g["ì¤‘ë¶„ë¥˜_ì „ì²´ë¹„ì¤‘"] = (
        pd.to_numeric(g["ëŒ€ë¶„ë¥˜ ì§€ì¶œì•¡ ë¹„ìœ¨"], errors="coerce")/100.0 *
        pd.to_numeric(g["ì¤‘ë¶„ë¥˜ ì§€ì¶œì•¡ ë¹„ìœ¨"], errors="coerce")/100.0
    )
    g = g.groupby(["ëŒ€ë¶„ë¥˜","ì¤‘ë¶„ë¥˜"], as_index=False)["ì¤‘ë¶„ë¥˜_ì „ì²´ë¹„ì¤‘"].sum() \
         .sort_values("ì¤‘ë¶„ë¥˜_ì „ì²´ë¹„ì¤‘", ascending=False).head(topn)
    return g

if st.session_state.selected_region:
    tabs = st.tabs(["ì—…ì¢… ê¸°ì¤€(PLP_ì—…ì¢…ë³„)", "ìœ í˜• ê¸°ì¤€(PLP_ìœ í˜•ë³„)"])
    with tabs[0]:
        top_cat = top_keywords(cat, st.session_state.selected_region, sel_big, kw, topn=12)
        st.dataframe(top_cat, use_container_width=True)
        st.bar_chart(top_cat.set_index("ì¤‘ë¶„ë¥˜")["ì¤‘ë¶„ë¥˜_ì „ì²´ë¹„ì¤‘"])
    with tabs[1]:
        sel_big2 = st.selectbox("ëŒ€ë¶„ë¥˜ ì„ íƒ(ìœ í˜•)", ["--ì „ì²´--"] + sorted(typ["ëŒ€ë¶„ë¥˜"].cat.categories.tolist()), key="type_big")
        kw2 = st.text_input("í‚¤ì›Œë“œ(ì¤‘ë¶„ë¥˜ëª… ë¶€ë¶„ ì¼ì¹˜)", "", key="type_kw")
        top_typ = top_keywords(typ, st.session_state.selected_region, sel_big2, kw2, topn=12)
        st.dataframe(top_typ, use_container_width=True)
        st.bar_chart(top_typ.set_index("ì¤‘ë¶„ë¥˜")["ì¤‘ë¶„ë¥˜_ì „ì²´ë¹„ì¤‘"])
else:
    st.info("ì§€ë„ì—ì„œ ì˜ì—­ì„ í´ë¦­í•˜ê±°ë‚˜, ìš°ì¸¡ íŒ¨ë„Â·ë“œë¡­ë‹¤ìš´ì„ ì´ìš©í•´ ì§€ì—­ì„ ì„ íƒí•˜ì„¸ìš”.")

st.markdown("""
---
**ë°ì´í„° ì¶œì²˜**  
- ê´€ê´‘ ë°ì´í„°ë©: ê´‘ì—­ë³„ ë°©ë¬¸ì ìˆ˜  
- PLP ë°ì´í„°: ì—…ì¢…/ìœ í˜•ë³„ ì§€ì¶œë¹„ì¤‘(ê²€ìƒ‰ ë¹„ì¤‘ ê¸°ë°˜)
""")
